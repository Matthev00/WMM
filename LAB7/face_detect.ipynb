{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Matthev00/WMM/blob/main/LAB7/face_detect.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIjIxfjUx1pF"
      },
      "source": [
        "## WMM - LAB7\n",
        "Mateusz Ostaszewski 325203 14.05.2024 Grupa 102"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZln09l59xoe"
      },
      "source": [
        "# Analiza obrazu - detekcja twarzy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fcp9Z1Bb4LbJ"
      },
      "source": [
        "## Inicjalizacja\n",
        "import bibliotek, pobranie do lokalnego środowiska wykonawczego przykładowego obrazu testowego i modeli dla detektorów twarzy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5MZZR3fB8Ke",
        "outputId": "85448b2b-28e1-419e-c294-5ff4ae44202d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting insightface\n",
            "  Downloading insightface-0.7.3.tar.gz (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.5/439.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.25.2)\n",
            "Collecting onnx (from insightface)\n",
            "  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m64.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from insightface) (4.66.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from insightface) (2.31.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from insightface) (3.7.1)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.10/dist-packages (from insightface) (9.4.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from insightface) (1.11.4)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from insightface) (1.2.2)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from insightface) (0.19.3)\n",
            "Requirement already satisfied: easydict in /usr/local/lib/python3.10/dist-packages (from insightface) (1.13)\n",
            "Requirement already satisfied: cython in /usr/local/lib/python3.10/dist-packages (from insightface) (3.0.10)\n",
            "Requirement already satisfied: albumentations in /usr/local/lib/python3.10/dist-packages (from insightface) (1.3.1)\n",
            "Requirement already satisfied: prettytable in /usr/local/lib/python3.10/dist-packages (from insightface) (3.10.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (6.0.1)\n",
            "Requirement already satisfied: qudida>=0.0.4 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (0.0.4)\n",
            "Requirement already satisfied: opencv-python-headless>=4.1.1 in /usr/local/lib/python3.10/dist-packages (from albumentations->insightface) (4.9.0.80)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (3.3)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (2024.5.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image->insightface) (24.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (4.51.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->insightface) (2.8.2)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx->insightface) (3.20.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prettytable->insightface) (0.2.13)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->insightface) (2024.2.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->insightface) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->insightface) (1.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from qudida>=0.0.4->albumentations->insightface) (4.11.0)\n",
            "Building wheels for collected packages: insightface\n",
            "  Building wheel for insightface (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for insightface: filename=insightface-0.7.3-cp310-cp310-linux_x86_64.whl size=1054142 sha256=10af802e975977611540c22c9fd2a66e38c0feee7131dd70c45c005899d690ed\n",
            "  Stored in directory: /root/.cache/pip/wheels/e3/d0/80/e3773fb8b6d1cca87ea1d33d9b1f20a223a6493c896da249b5\n",
            "Successfully built insightface\n",
            "Installing collected packages: onnx, insightface\n",
            "Successfully installed insightface-0.7.3 onnx-1.16.0\n",
            "Collecting onnxruntime\n",
            "  Downloading onnxruntime-1.17.3-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from onnxruntime)\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.25)\n",
            "Requirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.25.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (3.20.3)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Installing collected packages: humanfriendly, coloredlogs, onnxruntime\n",
            "Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnxruntime-1.17.3\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "import dlib\n",
        "\n",
        "# biblioteka insightface wymaga zainstalowania\n",
        "!pip install insightface\n",
        "!pip install onnxruntime\n",
        "\n",
        "import insightface"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOEcibLF4TjE",
        "outputId": "4e053784-95c3-4b43-a7c3-86b92bd3f2f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1dKxVJO0n5O6VuiHDdvrS36touzAeCgbw\n",
            "To: /content/2_Demonstration_Demonstration_Or_Protest_2_58.jpg\n",
            "\r  0% 0.00/173k [00:00<?, ?B/s]\r100% 173k/173k [00:00<00:00, 45.3MB/s]\n"
          ]
        }
      ],
      "source": [
        "# obraz testowy\n",
        "# https://drive.google.com/file/d/1dKxVJO0n5O6VuiHDdvrS36touzAeCgbw/view?usp=sharing\n",
        "!gdown 1dKxVJO0n5O6VuiHDdvrS36touzAeCgbw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m_azgpXm6ACI",
        "outputId": "4d17f3aa-4de5-406f-ea70-4977be289108"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1k2J4-4yIXrFFHZUhFv4pCRqcl-wB2Ve9\n",
            "To: /content/haarcascade_frontalface_default.zip\n",
            "\r  0% 0.00/140k [00:00<?, ?B/s]\r100% 140k/140k [00:00<00:00, 72.6MB/s]\n",
            "Archive:  haarcascade_frontalface_default.zip\n",
            "replace haarcascade_frontalface_default.xml? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ],
      "source": [
        "# model detektora Haar\n",
        "# https://drive.google.com/file/d/1k2J4-4yIXrFFHZUhFv4pCRqcl-wB2Ve9/view?usp=sharing\n",
        "!gdown 1k2J4-4yIXrFFHZUhFv4pCRqcl-wB2Ve9\n",
        "!unzip haarcascade_frontalface_default.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fZ-hsrIy8FI5"
      },
      "outputs": [],
      "source": [
        "# model detektora MMOD (sieć neuronowa z biblioteki dlib)\n",
        "# https://drive.google.com/file/d/1gwFX_zny4A6DVkQ2gV2FlKY39qh1iDYj/view?usp=sharing\n",
        "!gdown 1gwFX_zny4A6DVkQ2gV2FlKY39qh1iDYj"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7sfZAz_YbKHq"
      },
      "outputs": [],
      "source": [
        "# modele detektora twarzy (siec neuronowa) z biblioteki insightface\n",
        "!gdown 1avyNxM0XoYh8YfxhhZoCvvI0lE7qT8Gy\n",
        "!unzip insightface.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuuO37VXWMxc"
      },
      "source": [
        "## Metryki\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zXuC993WPS6"
      },
      "outputs": [],
      "source": [
        "def calculate_recall(true_positives, false_negatives):\n",
        "    recall = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) != 0 else 0\n",
        "    return recall\n",
        "\n",
        "def calculate_precision(true_positives, false_positives):\n",
        "    precision = true_positives / (true_positives + false_positives) if (true_positives + false_positives) != 0 else 0\n",
        "    return precision\n",
        "\n",
        "def calculate_f1_score(true_positives, false_positives, true_negatives, false_negatives):\n",
        "    precision = calculate_precision(true_positives, false_positives)\n",
        "    recall = calculate_recall(true_positives, false_negatives)\n",
        "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) != 0 else 0\n",
        "    return f1_score\n",
        "\n",
        "def calculate_accuracy(true_positives, false_positives, true_negatives, false_negatives):\n",
        "    total_predictions = true_positives + false_positives + true_negatives + false_negatives\n",
        "    accuracy = (true_positives + true_negatives) / total_predictions if total_predictions != 0 else 0\n",
        "    return accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGxinETn5K15"
      },
      "source": [
        "## Obraz testowy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4u9aVxFOF_aZ"
      },
      "outputs": [],
      "source": [
        "img = cv2.imread(\"2_Demonstration_Demonstration_Or_Protest_2_58.jpg\")\n",
        "# przygotowanie obrazów: monochromatycznego i RGB (cv2.imread() zwraca obraz w formacie BGR - inna kolejność składowych)\n",
        "img_gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "cv2_imshow(img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OttR_7b_IKS7"
      },
      "source": [
        "## Kaskada Haara\n",
        "\n",
        "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/05/opencv-face-detection-with-haar-cascades/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VzJr4nUVCE_c"
      },
      "outputs": [],
      "source": [
        "# utworzenie i inicjalizacja detektora\n",
        "haar_detector = cv2.CascadeClassifier(\"haarcascade_frontalface_default.xml\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0uQ2T_C5GH7S"
      },
      "outputs": [],
      "source": [
        "# wywołanie detektora dla określonego obrazu (img_gray)\n",
        "# wynikiem jest lista prostokątów w formacie [x, y, width, height]\n",
        "haar_results = haar_detector.detectMultiScale(img_gray, scaleFactor=1.05,\n",
        "                                         minNeighbors=5, minSize=(30, 30),\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "print(len(haar_results))\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_haar = img.copy()\n",
        "for (x, y, w, h) in haar_results:\n",
        "  cv2.rectangle(img_haar, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "cv2_imshow(img_haar)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g40bL5_BWcq5"
      },
      "outputs": [],
      "source": [
        "print(calculate_accuracy(20, 3, 0, 81))\n",
        "print(calculate_f1_score(20, 3, 0, 81))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzeHDIrgOq2l"
      },
      "source": [
        "### Haar Results\n",
        "\n",
        "| Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|------------  |----|----|----|----------|----|\n",
        "|     101      | 20 | 81 |  3 | 0,19     | 0,32|\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rdWKPv1RIFkE"
      },
      "source": [
        "## Histogram zorientowanych gradientów (HOG) z maszyną wektorów nośnych (SVM)\n",
        "\n",
        "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eC4Tf9PnIRTj"
      },
      "outputs": [],
      "source": [
        "# utworzenie i inicjalizacja detektora\n",
        "hog_svm_detector = dlib.get_frontal_face_detector()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GEhDJvWYOmXO"
      },
      "outputs": [],
      "source": [
        "# wywołanie detektora dla określonego obrazu (img_rgb)\n",
        "# wynikiem jest lista obiektów rectangle, zawierających współrzędne lewego górnego i prawego dolnego narożnika prostokąta\n",
        "hog_svm_results = hog_svm_detector(img_rgb, 2)\n",
        "print(len(hog_svm_results))\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_hog_svm = img.copy()\n",
        "for rect in hog_svm_results:\n",
        "\tcv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_hog_svm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u9OaMGo4XP7O"
      },
      "outputs": [],
      "source": [
        "print(calculate_accuracy(29, 0, 0, 72))\n",
        "print(calculate_f1_score(29, 0, 0, 72))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLbQM_UhQ2F0"
      },
      "source": [
        "### HOG SVM Results\n",
        "\n",
        "| Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|------------  |----|----|----|----------|----|\n",
        "|     101      | 29 | 72 |  0 | 0,29     | 0,45|\n",
        "\n",
        "Przy wiekszym parametrze k-krotnego sklaowania mamy lepszy efekt ale zajmuje to zdecydowanie wiecej czasu optymalna okazuje sie wartość 2."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-05vni26Px5J"
      },
      "source": [
        "## Splotowa sieć neuronowa (CNN) z biblioteki dlib\n",
        "\n",
        "Opracowano na podstawie: https://www.pyimagesearch.com/2021/04/19/face-detection-with-dlib-hog-and-cnn/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JSmzL4FxPLaA"
      },
      "outputs": [],
      "source": [
        "# utworzenie i inicjalizacja detektora\n",
        "cnn1_detector = dlib.cnn_face_detection_model_v1('mmod_human_face_detector.dat')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kgPDzLrAStOF"
      },
      "outputs": [],
      "source": [
        "# wywołanie detektora dla określonego obrazu (img_rgb)\n",
        "# wynikiem jest lista obiektów mmod_rectangle, zawierających m.in. pole rect ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
        "cnn1_results = cnn1_detector(img_rgb, 3)\n",
        "print(len(cnn1_results))\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_cnn1 = img.copy()\n",
        "for res in cnn1_results:\n",
        "\trect = res.rect\n",
        "\tcv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_cnn1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0oN4DsYQXkyt"
      },
      "outputs": [],
      "source": [
        "print(calculate_accuracy(46, 0, 0, 55))\n",
        "print(calculate_f1_score(46, 0, 0, 55))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PbU-H8rnR8sd"
      },
      "source": [
        "### CNN Results\n",
        "\n",
        "| Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|------------  |----|----|----|----------|----|\n",
        "|     101      | 46 | 55 |  0 | 0,46     | 0,63|\n",
        "\n",
        "Przy wiekszym parametrze k-krotnego sklaowania mamy lepszy efekt ale zajmuje to wiecej czasu(ale mniej niż w HOG SVM). Optymalna okazuje sie wartość 3."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ghePuqG7IsXY"
      },
      "source": [
        "## InsightFace - inna sieć neuronowa\n",
        "\n",
        "Opracowano na podstawie: https://github.com/deepinsight/insightface/tree/master/python-package"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u0pZhLPDqXuP"
      },
      "outputs": [],
      "source": [
        "# utworzenie i inicjalizacja detektora\n",
        "model_name = 'buffalo_s'  # model: small (_s), medium (_m) lub large (_l)\n",
        "insf_detector = insightface.app.FaceAnalysis(name=model_name, root='insightface',\n",
        "                                             allowed_modules=['detection'], providers=['CPUExecutionProvider'])\n",
        "insf_detector.prepare(ctx_id=0, det_size=(1024, 1024))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1czShMPI8FZ"
      },
      "outputs": [],
      "source": [
        "# wywołanie detektora dla określonego obrazu (img_rgb)\n",
        "# wynikiem jest lista obiektów, zawierających m.in. pole bbox ze współrzędnymi lewego górnego i prawego dolnego narożnika prostokąta\n",
        "insf_results = insf_detector.get(img)\n",
        "print(len(insf_results))\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_insf = img.copy()\n",
        "for res in insf_results:\n",
        "  # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
        "  rect = res.bbox.round().astype(int)\n",
        "  cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
        "cv2_imshow(img_insf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jzOI2OQKX1jq"
      },
      "outputs": [],
      "source": [
        "print(calculate_accuracy(56, 0, 0, 45))\n",
        "print(calculate_f1_score(56, 0, 0, 45))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cjxvNRuXTT0X"
      },
      "source": [
        "### InsightFace Results\n",
        "\n",
        "| Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|------------  |----|----|----|----------|----|\n",
        "|     101      | 56 | 45 |  0 |0.55|0.71|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lv64Bn3HTfL0"
      },
      "source": [
        "# WYNIKI ZAD1\n",
        "|             | Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|-------------|------------  |----|----|----|----------|----|\n",
        "| Haar        |     101      | 20 | 81 |  3 | 0,19     |0,32|\n",
        "| HOG SVM     |     101      | 29 | 72 |  0 | 0,29     |0,45|\n",
        "| CNN         |     101      | 46 | 55 |  0 | 0,46     |0,63|\n",
        "| InsightFace |     101      | 56 | 45 |  0 | 0.55     |0.71|\n",
        "\n",
        "Najskuteczniejsze okazują sie sieci neuronowe w szczegolności InsightFace, CNN(3) rownież ma potencjał. Parametr k-krotnej walidacji powyżej 3 powoduje bardzo wolne przetwarzanie obrazu, ktore jest niepraktyczne w większości zastosowań."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "td12lZeYbYLV"
      },
      "source": [
        "#ZAD2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MCSXEB2Tbbw5"
      },
      "source": [
        "## Wczytanie zdjęć"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gBdUudgcTXq6"
      },
      "outputs": [],
      "source": [
        "img1 = cv2.imread(\"/content/12_Group_Group_12_Group_Group_12_478.jpg\")\n",
        "img_gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\n",
        "img_rgb1 = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB)\n",
        "num_img1_faces =  5\n",
        "\n",
        "img2 = cv2.imread(\"/content/20_Family_Group_Family_Group_20_447.jpg\")\n",
        "img_gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)\n",
        "img_rgb2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB)\n",
        "num_img2_faces = 6\n",
        "\n",
        "img3 = cv2.imread(\"/content/8_Election_Campain_Election_Campaign_8_236.jpg\")\n",
        "img_gray3 = cv2.cvtColor(img3, cv2.COLOR_BGR2GRAY)\n",
        "img_rgb3 = cv2.cvtColor(img3, cv2.COLOR_BGR2RGB)\n",
        "num_img3_faces = 5\n",
        "\n",
        "\n",
        "# cv2_imshow(img1)\n",
        "# cv2_imshow(img2)\n",
        "cv2_imshow(img3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPTA-VWWoD36"
      },
      "source": [
        "## IMG 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZk4Iv73nseF"
      },
      "outputs": [],
      "source": [
        "haar_results = haar_detector.detectMultiScale(img_gray1, scaleFactor=1.05,\n",
        "                                        minNeighbors=5, minSize=(30, 30),\n",
        "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "img_haar1 = img1.copy()\n",
        "for (x, y, w, h) in haar_results:\n",
        "  cv2.rectangle(img_haar1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "cv2_imshow(img_haar1)\n",
        "print(len(haar_results))\n",
        "print(calculate_accuracy(2, 0, 0, num_img1_faces - len(haar_results)))\n",
        "print(calculate_f1_score(2, 0, 0, num_img1_faces - len(haar_results)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK4FOtIarsA9"
      },
      "outputs": [],
      "source": [
        "hog_svm_results = hog_svm_detector(img_rgb1, 2)\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_hog_svm = img1.copy()\n",
        "for rect in hog_svm_results:\n",
        "  cv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_hog_svm)\n",
        "faces = len(hog_svm_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img1_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img1_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8i7z6y16sb3C"
      },
      "outputs": [],
      "source": [
        "cnn1_results = cnn1_detector(img_rgb1, 3)\n",
        "\n",
        "img_cnn1 = img1.copy()\n",
        "for res in cnn1_results:\n",
        "\trect = res.rect\n",
        "\tcv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_cnn1)\n",
        "faces = len(cnn1_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img1_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img1_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vksnDDdPtuy_"
      },
      "outputs": [],
      "source": [
        "insf_results = insf_detector.get(img1)\n",
        "\n",
        "img_insf = img1.copy()\n",
        "for res in insf_results:\n",
        "  # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
        "  rect = res.bbox.round().astype(int)\n",
        "  cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
        "cv2_imshow(img_insf)\n",
        "faces = len(insf_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img1_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img1_faces - faces))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bfX0o9Knn5b"
      },
      "source": [
        "### Wnioski\n",
        "|             | Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|-------------|------------  |----|----|----|----------|----|\n",
        "| Haar        |     5        | 2  | 3  |  0 | 0,4      |0,57|\n",
        "| HOG SVM     |     5        | 3  | 2  |  0 | 0,6      |0,75|\n",
        "| CNN         |     5        | 4  | 1  |  0 | 0,8      |0,89|\n",
        "| InsightFace |     5        | 3  | 2  |  0 | 0,6      |0,75|\n",
        "\n",
        "Najlepsza okazała się sieć CNN. Zaskakujące może być to że HOG SVM był równie dobry co InsightFace."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SRO6AFcSuKc4"
      },
      "source": [
        "## IMG 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oJoHoKRruHLc"
      },
      "outputs": [],
      "source": [
        "haar_results = haar_detector.detectMultiScale(img_gray2, scaleFactor=1.05,\n",
        "                                        minNeighbors=5, minSize=(30, 30),\n",
        "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "img_haar1 = img2.copy()\n",
        "for (x, y, w, h) in haar_results:\n",
        "  cv2.rectangle(img_haar1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "cv2_imshow(img_haar1)\n",
        "print(1)\n",
        "print(calculate_accuracy(1, 3, 0, 5))\n",
        "print(calculate_f1_score(1, 3, 0, 5))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RqQBzDDhvwl6"
      },
      "outputs": [],
      "source": [
        "hog_svm_results = hog_svm_detector(img_rgb2, 2)\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_hog_svm = img2.copy()\n",
        "for rect in hog_svm_results:\n",
        "  cv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_hog_svm)\n",
        "faces = len(hog_svm_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img2_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img2_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tTE-EBbcv_Yx"
      },
      "outputs": [],
      "source": [
        "cnn1_results = cnn1_detector(img_rgb2, 3)\n",
        "\n",
        "img_cnn1 = img2.copy()\n",
        "for res in cnn1_results:\n",
        "\trect = res.rect\n",
        "\tcv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_cnn1)\n",
        "faces = len(cnn1_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(3, 1, 0, 3))\n",
        "print(calculate_f1_score(3, 1, 0, 3))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QEZ7KK2wwdYD"
      },
      "outputs": [],
      "source": [
        "insf_results = insf_detector.get(img2)\n",
        "\n",
        "img_insf = img2.copy()\n",
        "for res in insf_results:\n",
        "  # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
        "  rect = res.bbox.round().astype(int)\n",
        "  cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
        "cv2_imshow(img_insf)\n",
        "faces = len(insf_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img2_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img2_faces - faces))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ky4dEG1UvV-k"
      },
      "source": [
        "### Wnioski\n",
        "|             | Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|-------------|------------  |----|----|----|----------|----|\n",
        "| Haar        |     6        | 1  | 5  |  3 | 0,1      |0,2 |\n",
        "| HOG SVM     |     6        | 1  | 5  |  0 | 0,17     |0,29|\n",
        "| CNN         |     6        | 4  | 2  |  1 | 0,43     |0,6 |\n",
        "| InsightFace |     6        | 3  | 3  |  0 | 0,5      |0,66|\n",
        "\n",
        "Choć obraz wydaje się prosty do zadania detekcji wyniki mówią co innego. Najlepiej jak zwykle sprawdzily się sieci neuronowe w szczególności InsightFace. Widzimy też dużą skłonnośc algorytmu Haar do FP."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T4GChJcPywia"
      },
      "source": [
        "## IMG 3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gjs2Y9bBxpvr"
      },
      "outputs": [],
      "source": [
        "haar_results = haar_detector.detectMultiScale(img_gray3, scaleFactor=1.05,\n",
        "                                        minNeighbors=5, minSize=(30, 30),\n",
        "                                        flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "img_haar1 = img3.copy()\n",
        "for (x, y, w, h) in haar_results:\n",
        "  cv2.rectangle(img_haar1, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
        "cv2_imshow(img_haar1)\n",
        "faces = 2\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 2, 0, num_img3_faces - faces))\n",
        "print(calculate_f1_score(faces, 2, 0, num_img3_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "at516uZCzP7F"
      },
      "outputs": [],
      "source": [
        "hog_svm_results = hog_svm_detector(img_rgb3, 2)\n",
        "\n",
        "# narysowanie wyników na kopii obrazu i wyświetlenie\n",
        "img_hog_svm = img3.copy()\n",
        "for rect in hog_svm_results:\n",
        "  cv2.rectangle(img_hog_svm, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_hog_svm)\n",
        "faces = len(hog_svm_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img3_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img3_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W-vX9yDZ0WUA"
      },
      "outputs": [],
      "source": [
        "cnn1_results = cnn1_detector(img_rgb3, 3)\n",
        "\n",
        "img_cnn1 = img3.copy()\n",
        "for res in cnn1_results:\n",
        "\trect = res.rect\n",
        "\tcv2.rectangle(img_cnn1, (rect.left(), rect.top()), (rect.right(), rect.bottom()), (0, 255, 0), 2)\n",
        "cv2_imshow(img_cnn1)\n",
        "faces = len(cnn1_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img3_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img3_faces - faces))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEuBAgnn0Tyg"
      },
      "outputs": [],
      "source": [
        "insf_results = insf_detector.get(img3)\n",
        "\n",
        "img_insf = img3.copy()\n",
        "for res in insf_results:\n",
        "  # współrzędne prostokątów sa zapisane jako liczby rzeczywiste - konwersja do liczb całkowitych\n",
        "  rect = res.bbox.round().astype(int)\n",
        "  cv2.rectangle(img_insf, (rect[0], rect[1]), (rect[2], rect[3]), (0, 255, 0), 2)\n",
        "cv2_imshow(img_insf)\n",
        "faces = len(insf_results)\n",
        "print(faces)\n",
        "print(calculate_accuracy(faces, 0, 0, num_img3_faces - faces))\n",
        "print(calculate_f1_score(faces, 0, 0, num_img3_faces - faces))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iM3cg0-CzEUt"
      },
      "source": [
        "### Wnioski\n",
        "|             | Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|-------------|------------  |----|----|----|----------|----|\n",
        "| Haar        |     5        | 2  | 3  |  2 | 0,29     |0,44|\n",
        "| HOG SVM     |     5        | 1  | 4  |  0 | 0,2      |0,33|\n",
        "| CNN         |     5        | 4  | 1  |  0 | 0,8      |0,89|\n",
        "| InsightFace |     5        | 5  | 0  |  0 | 1        |1   |\n",
        "\n",
        "Detektor InsightFace w przypadku tego zdjecia okazal się bezbłędny. CCN też sobie dobrze poradził. HOG SVM i Haar okazały się na tym zdjęciu zdecydowanie gorsze."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPyG_N_d15E7"
      },
      "source": [
        "# ZAD3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-3NXYgmH1WkR"
      },
      "outputs": [],
      "source": [
        "total_acc_haar = calculate_accuracy(25, 8, 0, 92)\n",
        "total_acc_hog = calculate_accuracy(34, 0, 0, 83)\n",
        "total_acc_cnn = calculate_accuracy(58, 1, 0, 59)\n",
        "total_acc_if = calculate_accuracy(67, 0, 0, 50)\n",
        "print(total_acc_haar)\n",
        "print(total_acc_hog)\n",
        "print(total_acc_cnn)\n",
        "print(total_acc_if)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IX3xpZzM4Ojk"
      },
      "outputs": [],
      "source": [
        "total_f1_haar = calculate_f1_score(25, 8, 0, 92)\n",
        "total_f1_hog = calculate_f1_score(34, 0, 0, 83)\n",
        "total_f1_cnn = calculate_f1_score(58, 1, 0, 59)\n",
        "total_f1_if = calculate_f1_score(67, 0, 0, 50)\n",
        "print(total_f1_haar)\n",
        "print(total_f1_hog)\n",
        "print(total_f1_cnn)\n",
        "print(total_f1_if)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PavkE_2-2Anm"
      },
      "source": [
        "## Wnioski\n",
        "\n",
        "|             | Ground Truth | TP | FN | FP | Accuracy | F1 |\n",
        "|-------------|------------  |----|----|----|----------|----|\n",
        "| Haar        |     117      | 25 | 92 |  8 | 0,2      |0,33|\n",
        "| HOG SVM     |     117      | 34 | 83 |  0 | 0,29     |0,45|\n",
        "| CNN         |     117      | 58 | 59 |  1 | 0,49     |0,66|\n",
        "| InsightFace |     117      | 67 | 50 |  0 | 0,57     |0,73|\n",
        "\n",
        "Ze względu na dużą dysproporcję ilości twarzy na pierwszym zdjęciu w porównaniu do pozostałych, rezultaty są bardzo podobne do tych z ZAD 1. Podsumowując skuteczność modeli, można zauważyć, że InsightFace charakteryzuje się najlepszymi wynikami i wyraźnie wyróżnia się w detekcji \"trudnych\" zdjęć. Model CNN również osiąga dobre wyniki, szczególnie przy prostszych zdjęciach, gdzie może nawet przewyższać InsightFace.\n",
        "\n",
        "Z kolei modele Haar i HOG SVM mają zdecydowanie gorsze rezultaty. Algorytm Haar wykazuje największą tendencję do błędnego rozpoznawania części obrazu jako twarze (FP), co obniża jego skuteczność. HOG SVM również nie radzi sobie tak dobrze jak CNN czy InsightFace, zwłaszcza w przypadku zdjęć o wyższym stopniu trudności.\n",
        "\n",
        "Wyniki te wskazują, że dla zadań detekcji twarzy na złożonych obrazach InsightFace jest najbardziej efektywnym wyborem, a CNN może być dobrym rozwiązaniem w prostszych scenariuszach. Haar i HOG SVM natomiast mogą nie być wystarczająco precyzyjne w bardziej wymagających zastosowaniach."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nWk4B9jbu3IV"
      },
      "source": [
        "#ZAD4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKED_vQcv28S"
      },
      "outputs": [],
      "source": [
        "from timeit import default_timer as timer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_CDos6dmvz1s"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SSEAa9o84dJT"
      },
      "outputs": [],
      "source": [
        "iters = 5\n",
        "haar_times = []\n",
        "hog_svm_times_0 = []\n",
        "hog_svm_times_1 = []\n",
        "hog_svm_times_2 = []\n",
        "cnn_times_0 = []\n",
        "cnn_times_1 = []\n",
        "cnn_times_3 = []\n",
        "insightFace_times =[]\n",
        "for i in range(iters):\n",
        "  start = timer()\n",
        "  haar_detector.detectMultiScale(img_gray, scaleFactor=1.05,\n",
        "                                minNeighbors=5, minSize=(30, 30),\n",
        "                                flags=cv2.CASCADE_SCALE_IMAGE)\n",
        "  haar_times.append(timer()-start)\n",
        "\n",
        "  start = timer()\n",
        "  hog_svm_detector(img_rgb, 0)\n",
        "  hog_svm_times_0.append(timer()-start)\n",
        "\n",
        "  start = timer()\n",
        "  hog_svm_detector(img_rgb, 1)\n",
        "  hog_svm_times_1.append(timer()-start)\n",
        "\n",
        "  start = timer()\n",
        "  hog_svm_detector(img_rgb, 2)\n",
        "  hog_svm_times_2.append(timer()-start)\n",
        "\n",
        "  start = timer()\n",
        "  cnn1_detector(img_rgb, 0)\n",
        "  cnn_times_0.append(timer() - start)\n",
        "\n",
        "  start = timer()\n",
        "  cnn1_detector(img_rgb, 1)\n",
        "  cnn_times_1.append(timer() - start)\n",
        "\n",
        "  start = timer()\n",
        "  cnn1_detector(img_rgb, 3)\n",
        "  cnn_times_3.append(timer() - start)\n",
        "\n",
        "  start = timer()\n",
        "  insf_detector.get(img)\n",
        "  insightFace_times.append(timer() - start)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80kZw-UmzaD5"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_detection_times(haar_times, hog_svm_times_0, hog_svm_times_1, hog_svm_times_2, cnn_times_0, cnn_times_1, cnn_times_3, insightFace_times):\n",
        "    iters = len(haar_times)\n",
        "    x = range(iters)\n",
        "\n",
        "    plt.figure(figsize=(14, 8))\n",
        "\n",
        "    # Plotting Haar times\n",
        "    plt.plot(x, haar_times, label='Haar')\n",
        "\n",
        "    # Plotting HOG + SVM times\n",
        "    plt.plot(x, hog_svm_times_0, label='HOG + SVM (0)')\n",
        "    plt.plot(x, hog_svm_times_1, label='HOG + SVM (1)')\n",
        "    plt.plot(x, hog_svm_times_2, label='HOG + SVM (2)')\n",
        "\n",
        "    # Plotting CNN times\n",
        "    plt.plot(x, cnn_times_0, label='CNN (0)')\n",
        "    plt.plot(x, cnn_times_1, label='CNN (1)')\n",
        "    plt.plot(x, cnn_times_3, label='CNN (3)')\n",
        "\n",
        "    # Plotting InsightFace times\n",
        "    plt.plot(x, insightFace_times, label='InsightFace')\n",
        "\n",
        "    plt.xlabel('Iteration')\n",
        "    plt.ylabel('Detection Time (seconds)')\n",
        "    plt.title('Detection Times for Different Detectors')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VSJDZMbO0PMD"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "def print_detection_times_table(haar_times, hog_svm_times_0, hog_svm_times_1, hog_svm_times_2, cnn_times_0, cnn_times_1, cnn_times_3, insightFace_times):\n",
        "    data = {\n",
        "        'Iteration': list(range(1, len(haar_times) + 1)),\n",
        "        'Haar': haar_times,\n",
        "        'HOG + SVM (0)': hog_svm_times_0,\n",
        "        'HOG + SVM (1)': hog_svm_times_1,\n",
        "        'HOG + SVM (2)': hog_svm_times_2,\n",
        "        'CNN (0)': cnn_times_0,\n",
        "        'CNN (1)': cnn_times_1,\n",
        "        'CNN (3)': cnn_times_3,\n",
        "        'InsightFace': insightFace_times\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # Calculate means\n",
        "    mean_row = df.mean(numeric_only=True).to_frame().T\n",
        "    mean_row['Iteration'] = 'Mean'\n",
        "\n",
        "    # Append the mean row to the dataframe\n",
        "    df = pd.concat([df, mean_row], ignore_index=True)\n",
        "\n",
        "    print(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vu2lVfIKybWF"
      },
      "outputs": [],
      "source": [
        "plot_detection_times(haar_times, hog_svm_times_0, hog_svm_times_1, hog_svm_times_2, cnn_times_0, cnn_times_1, cnn_times_3, insightFace_times)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QLX6k_aVz4bk"
      },
      "outputs": [],
      "source": [
        "print_detection_times_table(haar_times, hog_svm_times_0, hog_svm_times_1, hog_svm_times_2, cnn_times_0, cnn_times_1, cnn_times_3, insightFace_times)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eE0Aii27z308"
      },
      "source": [
        "##Wnioski\n",
        "Na wygenerowanym wykresie można zauważyć, że czasy działania większości detektorów są stabilne, z wyjątkiem algorytmu Haar, który wykazuje pewne wahania, oraz detektora HOG SVM z parametrem skalowania równym 2. Analiza średnich czasów zamieszczonych w tabeli oraz wykresu wskazuje, że parametr skalowania ma istotny wpływ na czas działania zarówno w przypadku detektorów CNN, jak i HOG SVM – im większy parametr skalowania, tym dłuższy czas działania.\n",
        "\n",
        "Przy porównaniu czasów działania i skuteczności różnych detektorów, model InsightFace wypada bardzo korzystnie. Charakteryzuje się on krótkim czasem wykrywania, co w połączeniu z wysoką skutecznością czyni go bardzo efektywnym narzędziem w zadaniach detekcji.\n",
        "\n",
        "Użyte środowisko to: Google Compute Engine języka Python 3 z układem (GPU) Nvidia T4"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "td12lZeYbYLV"
      ],
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}